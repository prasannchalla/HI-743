---
title: "Linear Regression R"
author: "Lakshmi Prasanna Challa"
date: "2025-02-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

install.packages("ISLR2")
library(ISLR2)
```

# Boston Dataset Analysis

### Objective

How can we predict the Median Value of Owner_Occupied Homes using the lower Status

\<what are we analyzing? Why? What insight can we gain from this analysis.

### Data Understand and preparation

\<What kinds of variables do we have? What kind of questions can we answer further with this data?\>

### Data Loading

\<What does the summary say about this date?\>

```{r load.data}
data(Boston)
glimpse(Boston)

summary(Boston)
```

### Data exploration

```{r missing values}
missing_values = Boston %>%
  summarise(across(everything(), ~ sum(is.na(.))))
print(missing_values)
```

### Train-Test Split

\<How does this technique aid our analysis, especially given new data?\>

```{r train-test}
set.seed(123) # For reproducibility
Boston_split = Boston %>%
  mutate(id = row_number()) %>%
  sample_frac(0.75)

Boston = Boston %>% mutate(id = row_number())

train_data = Boston_split
test_data = anti_join(Boston, Boston_split, by = "id") #Remaining 25%
```

### Exploratory Data Analysis

\<what figures did we build?Why? What information do they convey? How it is important to the analysis?\>

```{r histogram for medv}
ggplot(Boston, aes(x = medv)) +
  geom_histogram(fill = "steelblue", binwidth = 2, color = "white") +
  labs(title = "distribution of Median Home Values",
       x = "Median value ($1000s)",
       y = "Count")

```

```{r LSTAT vs MEDV Scatterplot}
ggplot(Boston, aes(x = lstat, y=medv)) +
  geom_point(alpha = 0.6, color = 'blue') +
  labs(title = "Scatterplot: LSTAT vs. MEDV",
       x = "Lower Status Population",
       y = "Median Home Value ($1000s)")

```

### Model Implementation & Explanation

\<what model are we using? why does this/these model(s) apply to the data?What are the pros & cons of this type of model? \>

### Perform simple Linear Regression on Training Data

\<Describe the function & model fit. maybe talk about the evaluation metrics?\>

```{r Liunear Regression}
lm.fit = lm(medv ~ lstat, data = train_data)
summary(lm.fit)
```

Could built a scatter plot with this regression line onto it.

### Apply Model to Test Data

\<could interpret the Test MSE\>

```{r apply model to test_data}
train_mse = mean((train_data$medv - predict(lm.fit, train_data))^2)
test_mse = mean((test_data$medv - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

### Simple Linear Regression results & interpretation

\<Overall, how good is this fit? What does it say about the data and the question being asked?\>

### Perform Multiple Linear Regression on Training Data

\<what question does this model answer?\>

```{r}
lm.multiple.fit = lm(medv ~ lstat + age, data = train_data)  
summary(lm.multiple.fit)
```

### Apply the Model to Test Data

```{r}
train_mse = mean((train_data$medv - predict(lm.multiple.fit, train_data))^2)
test_mse = mean((test_data$medv - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

## NHANES Data Analysis

## Objective

please predict BMI using Age, SmokeNow, PhysActive for induviduals between the ages of 18 and 70

## Data understanding & Preparation

## Data loading

```{r}
#install.packages("NHANES")
library(NHANES)
data(NHANES)

SMOKERS = NHANES %>%
  select(BMI, Age, SmokeNow, PhysActive) %>%
  filter(Age >= 18 & Age <= 70)
```

## Data Exploration

```{r}
# Check for missing values in the selected data
missing_values <- SMOKERS %>%
  summarise(across(everything(), ~ sum(is.na(.))))

print(missing_values)
```

## Handling Missing Data

```{r}
# Remove rows with missing or non-finite values
SMOKERS <- SMOKERS %>%
  filter(!is.na(BMI) & !is.na(Age) & !is.na(SmokeNow) & !is.na(PhysActive))

# Confirm data cleaning
print(nrow(SMOKERS))  # Remaining rows after cleaning
```

## Train - Test Split

```{r}
# Set seed for reproducibility
set.seed(123)

# Add the 'id' column to the original dataset (SMOKERS)
SMOKERS <- SMOKERS %>% mutate(id = row_number())

# Split the data into 75% training and 25% testing
SMOKERS_split <- SMOKERS %>%
  sample_frac(0.75)  # 75% for training data

# The remaining 25% will be for testing
test_data <- anti_join(SMOKERS, SMOKERS_split, by = "id")  # Join using 'id' column
train_data <- SMOKERS_split
```

## Exploratory Data Analysis

```{r}
# Plot the distribution of BMI
library(ggplot2)

ggplot(SMOKERS, aes(x = BMI)) +
  geom_histogram(fill = "steelblue", binwidth = 5, color = "white") +
  labs(title = "Distribution of BMI", x = "BMI", y = "Count")
```

## Scatterplot: Age vs. BMI

This helps in visualizing the relationship between **Age** and **BMI**.

```{r}
# Scatterplot: Age vs. BMI
ggplot(SMOKERS, aes(x = Age, y = BMI)) +
  geom_point(alpha = 0.6, color = 'blue') +
  labs(title = "Scatterplot: Age vs. BMI", x = "Age", y = "BMI")
```

## Scatterplot: SmokeNow vs. BMI

```{r}
# Scatterplot: SmokeNow vs. BMI
ggplot(SMOKERS, aes(x = SmokeNow, y = BMI)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Boxplot: SmokeNow vs. BMI", x = "SmokeNow", y = "BMI")
```

## Model Implementation

### Perform simple Linear Regression on Training Data

```{r}
#Fit a Simple Linear Regression Model ---
lm.fit <- lm(BMI ~ Age, data = train_data)

# View Model Summary
summary(lm.fit)
```

### Apply Model to Text Data

```{r}
train_mse = mean((train_data$BMI - predict(lm.fit, train_data))^2)
test_mse = mean((test_data$BMI - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

### **Simple Linear Regression Results & Interpretation**

-   **Training MSE: 42.98**\
    The model has an average squared error of 42.98 on the training data, indicating a moderate fit.

-   **Test MSE: 34.98**\
    The model performs slightly better on the test data with an average squared error of 34.98, suggesting it generalizes well to new, unseen data.

-   **Conclusion**: The model has a reasonable fit with no significant overfitting, as the Training and Test MSEs are close. There's potential for improvement by adding more predictors or using more complex models.

### Perform Multiple Linear Regression on Training Data

```{r}
lm.multiple.fit = lm(BMI ~ Age + SmokeNow + PhysActive, data = train_data)  
summary(lm.multiple.fit)
```

### Apply the Model to Test Data

```{r}
train_mse = mean((train_data$BMI - predict(lm.multiple.fit, train_data))^2)
test_mse = mean((test_data$BMI - predict(lm.multiple.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))

```

### **Multiple Linear Regression Results & Interpretation**

-   **Training MSE: 41.57**\
    The model has an average squared error of 41.57 on the training data, indicating a decent fit, but there's still room for improvement.

-   **Test MSE: 33.69**\
    The model performs slightly better on the test data with an average squared error of 33.69, suggesting good generalization to unseen data.

-   **Conclusion**: The **Multiple Linear Regression** model provides a better fit compared to the **Simple Linear Regression**, as the **Test MSE** is lower. The model is not overfitting, and it seems to generalize well. However, further improvements could be made by considering additional predictor variables or more advanced techniques.
