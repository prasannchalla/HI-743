---
title: "Linear Regression R"
author: "Lakshmi Prasanna Challa"
date: "2025-02-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

#install.packages("ISLR2")
library(ISLR2)
```

# Boston Dataset Analysis

### Objective

How can we predict the Median Value of Owner_Occupied Homes using the lower Status

\<what are we analyzing? Why? What insight can we gain from this analysis.

### Data Understand and preparation

\<What kinds of variables do we have? What kind of questions can we answer further with this data?\>

### Data Loading

\<What does the summary say about this date?\>

```{r load.data}
data(Boston)
glimpse(Boston)

summary(Boston)
```

### Data exploration

```{r missing values}
missing_values = Boston %>%
  summarise(across(everything(), ~ sum(is.na(.))))
print(missing_values)
```

### Train-Test Split

\<How does this technique aid our analysis, especially given new data?\>

```{r train-test}
set.seed(123) # For reproducibility
Boston_split = Boston %>%
  mutate(id = row_number()) %>%
  sample_frac(0.75)

Boston = Boston %>% mutate(id = row_number())

train_data = Boston_split
test_data = anti_join(Boston, Boston_split, by = "id") #Remaining 25%
```

### Exploratory Data Analysis

\<what figures did we build?Why? What information do they convey? How it is important to the analysis?\>

```{r histogram for medv}
ggplot(Boston, aes(x = medv)) +
  geom_histogram(fill = "steelblue", binwidth = 2, color = "white") +
  labs(title = "distribution of Median Home Values",
       x = "Median value ($1000s)",
       y = "Count")

```

```{r LSTAT vs MEDV Scatterplot}
ggplot(Boston, aes(x = lstat, y=medv)) +
  geom_point(alpha = 0.6, color = 'blue') +
  labs(title = "Scatterplot: LSTAT vs. MEDV",
       x = "Lower Status Population",
       y = "Median Home Value ($1000s)")

```

### Model Implementation & Explanation

\<what model are we using? why does this/these model(s) apply to the data?What are the pros & cons of this type of model? \>

### Perform simple Linear Regression on Training Data

\<Describe the function & model fit. maybe talk about the evaluation metrics?\>

```{r Liunear Regression}
lm.fit = lm(medv ~ lstat, data = train_data)
summary(lm.fit)
```

Could built a scatter plot with this regression line onto it.

### Apply Model to Test Data

\<could interpret the Test MSE\>

```{r apply model to test_data}
train_mse = mean((train_data$medv - predict(lm.fit, train_data))^2)
test_mse = mean((test_data$medv - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

### Simple Linear Regression results & interpretation

\<Overall, how good is this fit? What does it say about the data and the question being asked?\>

### Perform Multiple Linear Regression on Training Data

\<what question does this model answer?\>

```{r}
lm.multiple.fit = lm(medv ~ lstat + age, data = train_data)  
summary(lm.multiple.fit)
```

### Apply the Model to Test Data

```{r}
train_mse = mean((train_data$medv - predict(lm.multiple.fit, train_data))^2)
test_mse = mean((test_data$medv - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

## NHANES Data Analysis

## 1. Objective

This analysis aims to predict **BMI** using **Age, Smoking Status (SmokeNow), and Physical Activity (PhysActive)** for individuals aged **18-70**.

### **1.1 What Are We Analyzing?**

We are examining how age, smoking habits, and physical activity influence BMI. Since BMI is a key health indicator, understanding these relationships can help identify factors contributing to weight changes and overall health risks.

### **1.2 Why Are We Conducting This Analysis?**

High BMI is linked to health conditions like **diabetes, heart disease, and hypertension**. Smoking affects metabolism and appetite, while physical activity plays a role in weight management. By analyzing these factors, we can gain insights into how lifestyle choices impact BMI and overall health.

### **1.3 What Insights Can We Gain?**

This study explores **how BMI changes with age, whether smokers have different BMI trends, and how physical activity influences weight**. The findings can support **personalized health recommendations** and inform **public health policies** for better weight management and disease prevention.

## 2. Data understanding & Preparation

### **2.1 Variables in the Dataset:**

-   **BMI** (Continuous) – Body Mass Index, the target variable.

-   **Age** (Continuous) – Age of individuals (18-70).

-   **SmokeNow** (Categorical) – Smoking status (Yes/No).

-   **PhysActive** (Categorical) – Physical activity level (Yes/No).

### **2.2 Key Questions We Can Answer:**

-   How does BMI change with age?

-   Do smokers tend to have higher or lower BMI?

-   What is the relationship between physical activity and BMI?

## 3. Data loading

The dataset is loaded from the **NHANES** package, containing health-related variables. A summary of the selected data (BMI, Age, SmokeNow, PhysActive) provides insights into its distribution, missing values, and overall trends. It helps identify potential data issues, such as outliers or gaps, ensuring the dataset is clean and suitable for analysis.

```{r}
#install.packages("NHANES")
library(NHANES)
data(NHANES)

SMOKERS = NHANES %>%
  select(BMI, Age, SmokeNow, PhysActive) %>%
  filter(Age >= 18 & Age <= 70)
```

## 4. Data Exploration

```{r}
# Check for missing values in the selected data
missing_values <- SMOKERS %>%
  summarise(across(everything(), ~ sum(is.na(.))))

print(missing_values)
```

## 5. Handling Missing Data

We handle missing data to avoid bias, loss of information, and poor model performance, ensuring accurate and reliable analysis.

```{r}
# Remove rows with missing or non-finite values
SMOKERS <- SMOKERS %>%
  filter(!is.na(BMI) & !is.na(Age) & !is.na(SmokeNow) & !is.na(PhysActive))

# Confirm data cleaning
print(nrow(SMOKERS))  # Remaining rows after cleaning
```

## 6. Train - Test Split

Splitting the data into **training (75%) and testing (25%) sets** helps evaluate the model's performance on unseen data. The training set is used to build the model, while the test set assesses its ability to generalize. This technique prevents **overfitting**, ensuring the model performs well on new data rather than just memorizing patterns from the training set.

```{r}
# Set seed for reproducibility
set.seed(123)

# Add the 'id' column to the original dataset (SMOKERS)
SMOKERS <- SMOKERS %>% mutate(id = row_number())

# Split the data into 75% training and 25% testing
SMOKERS_split <- SMOKERS %>%
  sample_frac(0.75)  # 75% for training data

# The remaining 25% will be for testing
test_data <- anti_join(SMOKERS, SMOKERS_split, by = "id")  # Join using 'id' column
train_data <- SMOKERS_split
```

## 7. Exploratory Data Analysis

In EDA, we use visualizations like histograms, box plots, and scatter plots to assess data distribution, relationships, and patterns, guiding analysis decisions.

```{r}
# Plot the distribution of BMI
library(ggplot2)

ggplot(SMOKERS, aes(x = BMI)) +
  geom_histogram(fill = "steelblue", binwidth = 5, color = "white") +
  labs(title = "Distribution of BMI", x = "BMI", y = "Count")
```

## 7.1 Scatterplot: Age vs. BMI

This helps in visualizing the relationship between **Age** and **BMI**.

```{r}
# Scatterplot: Age vs. BMI
ggplot(SMOKERS, aes(x = Age, y = BMI)) +
  geom_point(alpha = 0.6, color = 'blue') +
  labs(title = "Scatterplot: Age vs. BMI", x = "Age", y = "BMI")
```

## 7.2 Scatterplot: SmokeNow vs. BMI

A scatterplot of SmokeNow vs. BMI visualizes the relationship between smoking status and body mass index, helping identify any patterns or correlations.

```{r}
# Scatterplot: SmokeNow vs. BMI
ggplot(SMOKERS, aes(x = SmokeNow, y = BMI)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Boxplot: SmokeNow vs. BMI", x = "SmokeNow", y = "BMI")
```

## Model Implementation

We use **Simple Linear Regression** because it effectively predicts a continuous target based on a linear relationship with a single feature, offering simplicity and speed but being sensitive to outliers and limited by the assumption of linearity.

### Perform simple Linear Regression on Training Data

In simple linear regression, the model fits a line by minimizing squared errors, with evaluation metrics like **Mean Squared Error (MSE)**, which measures prediction accuracy, and **R-squared (**R2R2), which indicates how well the model explains the variance in the data.

```{r}
#Fit a Simple Linear Regression Model ---
lm.fit <- lm(BMI ~ Age, data = train_data)

# View Model Summary
summary(lm.fit)
```

### Apply Model to Text Data

```{r}
train_mse = mean((train_data$BMI - predict(lm.fit, train_data))^2)
test_mse = mean((test_data$BMI - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

### **Simple Linear Regression Results & Interpretation**

-   **Training MSE: 42.98**\
    The model has an average squared error of 42.98 on the training data, indicating a moderate fit.

-   **Test MSE: 34.98**\
    The model performs slightly better on the test data with an average squared error of 34.98, suggesting it generalizes well to new, unseen data.

-   **Conclusion**: The model has a reasonable fit with no significant overfitting, as the Training and Test MSEs are close. There's potential for improvement by adding more predictors or using more complex models.

### Perform Multiple Linear Regression on Training Data

```{r}
lm.multiple.fit = lm(BMI ~ Age + SmokeNow + PhysActive, data = train_data)  
summary(lm.multiple.fit)
```

### Apply the Model to Test Data

```{r}
train_mse = mean((train_data$BMI - predict(lm.multiple.fit, train_data))^2)
test_mse = mean((test_data$BMI - predict(lm.multiple.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))

```

### **Multiple Linear Regression Results & Interpretation**

-   **Training MSE: 41.57**\
    The model has an average squared error of 41.57 on the training data, indicating a decent fit, but there's still room for improvement.

-   **Test MSE: 33.69**\
    The model performs slightly better on the test data with an average squared error of 33.69, suggesting good generalization to unseen data.

-   **Conclusion**: The **Multiple Linear Regression** model provides a better fit compared to the **Simple Linear Regression**, as the **Test MSE** is lower. The model is not overfitting, and it seems to generalize well. However, further improvements could be made by considering additional predictor variables or more advanced techniques.
